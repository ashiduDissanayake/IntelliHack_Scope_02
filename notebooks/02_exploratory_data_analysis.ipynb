{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Segmentation - Exploratory Data Analysis (EDA)\n",
    "\n",
    "This notebook focuses on exploring the preprocessed customer behavior data to gain insights before applying clustering algorithms. We'll analyze:\n",
    "\n",
    "1. Feature distributions\n",
    "2. Correlation between features\n",
    "3. Feature relationships\n",
    "4. Dimensionality reduction using PCA\n",
    "5. Initial visual exploration for potential clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: plotly in /Users/ashidudissanayake/Library/Python/3.9/lib/python/site-packages (6.0.0)\n",
      "Requirement already satisfied: packaging in /Users/ashidudissanayake/Library/Python/3.9/lib/python/site-packages (from plotly) (24.2)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /Users/ashidudissanayake/Library/Python/3.9/lib/python/site-packages (from plotly) (1.29.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Set plotting style\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "import os\n",
    "\n",
    "# Set plotting style\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "\n",
    "# Increase default figure size\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs('./output', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed data\n",
    "preprocessed_file = './output/preprocessed_data.csv'\n",
    "df = pd.read_csv(preprocessed_file)\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also load the unscaled data for reference\n",
    "unscaled_file = './output/cleaned_data_unscaled.csv'\n",
    "df_unscaled = pd.read_csv(unscaled_file)\n",
    "\n",
    "# Display unscaled data\n",
    "print(\"Unscaled data (first few rows):\")\n",
    "df_unscaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and basic info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get statistical summary of preprocessed data\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns for analysis (exclude customer_id if present)\n",
    "feature_cols = [col for col in df.columns if col != 'customer_id']\n",
    "\n",
    "# Plot histograms of each feature\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "for i, col in enumerate(feature_cols):\n",
    "    plt.subplot(3, 2, i+1)\n",
    "    sns.histplot(df[col], kde=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.savefig('./output/feature_distributions.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of unscaled features for better interpretation\n",
    "unscaled_feature_cols = [col for col in df_unscaled.columns if col != 'customer_id']\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "for i, col in enumerate(unscaled_feature_cols):\n",
    "    plt.subplot(3, 2, i+1)\n",
    "    sns.histplot(df_unscaled[col], kde=True)\n",
    "    plt.title(f'Original Distribution of {col}')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.savefig('./output/original_feature_distributions.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create box plots to visualize feature distributions\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "for i, col in enumerate(feature_cols):\n",
    "    plt.subplot(3, 2, i+1)\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f'Box Plot of {col}')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('./output/feature_boxplots.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = df[feature_cols].corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0, fmt='.2f')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./output/correlation_heatmap.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify high correlations\n",
    "high_corr = []\n",
    "for i, row in enumerate(corr_matrix.values):\n",
    "    for j, corr in enumerate(row):\n",
    "        if i < j and abs(corr) > 0.5:  # Only upper triangle and significant correlations\n",
    "            high_corr.append((corr_matrix.index[i], corr_matrix.columns[j], corr))\n",
    "\n",
    "if high_corr:\n",
    "    print(\"Features with high correlation (|r| > 0.5):\")\n",
    "    for feature1, feature2, corr in high_corr:\n",
    "        print(f\"{feature1} and {feature2}: {corr:.3f}\")\n",
    "else:\n",
    "    print(\"No high correlations found between features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pairplot to visualize relationships between features\n",
    "sns.pairplot(df[feature_cols], diag_kind='kde')\n",
    "plt.suptitle(\"Pairwise Feature Relationships\", y=1.02, fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./output/pairplot.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some specific scatter plots based on domain knowledge\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Plot 1: total_purchases vs avg_cart_value\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.scatterplot(x='total_purchases', y='avg_cart_value', data=df_unscaled, alpha=0.7)\n",
    "plt.title('Total Purchases vs Average Cart Value')\n",
    "plt.xlabel('Total Purchases')\n",
    "plt.ylabel('Average Cart Value')\n",
    "\n",
    "# Plot 2: total_time_spent vs product_click\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.scatterplot(x='total_time_spent', y='product_click', data=df_unscaled, alpha=0.7)\n",
    "plt.title('Time Spent vs Product Clicks')\n",
    "plt.xlabel('Total Time Spent (minutes)')\n",
    "plt.ylabel('Product Clicks')\n",
    "\n",
    "# Plot 3: discount usage vs avg_cart_value\n",
    "discount_col = 'discount_counts' if 'discount_counts' in df_unscaled.columns else 'discount_count'\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.scatterplot(x=discount_col, y='avg_cart_value', data=df_unscaled, alpha=0.7)\n",
    "plt.title('Discount Usage vs Average Cart Value')\n",
    "plt.xlabel('Discount Usage Count')\n",
    "plt.ylabel('Average Cart Value')\n",
    "\n",
    "# Plot 4: total_purchases vs discount usage\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.scatterplot(x='total_purchases', y=discount_col, data=df_unscaled, alpha=0.7)\n",
    "plt.title('Total Purchases vs Discount Usage')\n",
    "plt.xlabel('Total Purchases')\n",
    "plt.ylabel('Discount Usage Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./output/key_feature_relationships.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dimensionality Reduction with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate PCA\n",
    "pca = PCA()\n",
    "principal_components = pca.fit_transform(df[feature_cols])\n",
    "\n",
    "# Calculate explained variance\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "# Print explained variance\n",
    "print(\"Explained variance ratio by component:\")\n",
    "for i, ratio in enumerate(explained_variance):\n",
    "    print(f\"PC{i+1}: {ratio:.4f} ({cumulative_variance[i]:.4f} cumulative)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot explained variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Individual explained variance\n",
    "plt.bar(range(1, len(explained_variance) + 1), \n",
    "        explained_variance, \n",
    "        alpha=0.7, \n",
    "        label='Individual explained variance')\n",
    "\n",
    "# Cumulative explained variance\n",
    "plt.step(range(1, len(cumulative_variance) + 1), \n",
    "         cumulative_variance, \n",
    "         where='mid', \n",
    "         label='Cumulative explained variance',\n",
    "         color='red')\n",
    "\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('PCA Explained Variance')\n",
    "plt.grid(linestyle='--', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('./output/pca_explained_variance.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with principal components\n",
    "pca_df = pd.DataFrame(\n",
    "    data=principal_components[:, :2],\n",
    "    columns=['PC1', 'PC2']\n",
    ")\n",
    "\n",
    "# Add customer_id if it exists in the original dataframe\n",
    "if 'customer_id' in df.columns:\n",
    "    pca_df['customer_id'] = df['customer_id'].values\n",
    "\n",
    "# Visualize the data in 2D PCA space\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(pca_df['PC1'], pca_df['PC2'], alpha=0.5)\n",
    "plt.title('PCA: First Two Principal Components')\n",
    "plt.xlabel(f'PC1 ({explained_variance[0]:.2%} variance)')\n",
    "plt.ylabel(f'PC2 ({explained_variance[1]:.2%} variance)')\n",
    "plt.grid(linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./output/pca_visualization.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive 3D scatter plot with the first three principal components\n",
    "if len(explained_variance) >= 3:\n",
    "    pca_3d_df = pd.DataFrame(\n",
    "        data=principal_components[:, :3],\n",
    "        columns=['PC1', 'PC2', 'PC3']\n",
    "    )\n",
    "    \n",
    "    fig = px.scatter_3d(\n",
    "        pca_3d_df, \n",
    "        x='PC1', \n",
    "        y='PC2', \n",
    "        z='PC3',\n",
    "        title='PCA: First Three Principal Components',\n",
    "        opacity=0.7,\n",
    "        labels={\n",
    "            'PC1': f'PC1 ({explained_variance[0]:.2%})',\n",
    "            'PC2': f'PC2 ({explained_variance[1]:.2%})',\n",
    "            'PC3': f'PC3 ({explained_variance[2]:.2%})'\n",
    "        }\n",
    "    )\n",
    "    fig.update_traces(marker=dict(size=5))\n",
    "    fig.write_html('./output/pca_3d_visualization.html')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and visualize feature loadings (coefficients)\n",
    "loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "loading_df = pd.DataFrame(\n",
    "    loadings, \n",
    "    columns=[f'PC{i+1}' for i in range(len(pca.components_))],\n",
    "    index=feature_cols\n",
    ")\n",
    "\n",
    "print(\"PCA Feature Loadings:\")\n",
    "print(loading_df)\n",
    "\n",
    "# Plot heatmap of feature loadings\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(loading_df, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "plt.title('PCA Feature Loadings')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./output/pca_loadings.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Initial Clustering Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a more detailed scatter plot with key features colored by potential groups\n",
    "# This can help identify potential customer segments visually\n",
    "\n",
    "# Example 1: Color by total_purchases\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.scatter(df_unscaled['avg_cart_value'], df_unscaled['total_time_spent'], \n",
    "            c=df_unscaled['total_purchases'], cmap='viridis', alpha=0.7, s=50)\n",
    "plt.colorbar(label='Total Purchases')\n",
    "plt.title('Potential Customer Segments by Total Purchases')\n",
    "plt.xlabel('Average Cart Value')\n",
    "plt.ylabel('Total Time Spent')\n",
    "plt.grid(linestyle='--', alpha=0.5)\n",
    "plt.savefig('./output/potential_segments_purchases.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Color by discount usage\n",
    "discount_col = 'discount_counts' if 'discount_counts' in df_unscaled.columns else 'discount_count'\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.scatter(df_unscaled['avg_cart_value'], df_unscaled['total_purchases'], \n",
    "            c=df_unscaled[discount_col], cmap='viridis', alpha=0.7, s=50)\n",
    "plt.colorbar(label='Discount Usage')\n",
    "plt.title('Potential Customer Segments by Discount Usage')\n",
    "plt.xlabel('Average Cart Value')\n",
    "plt.ylabel('Total Purchases')\n",
    "plt.grid(linestyle='--', alpha=0.5)\n",
    "plt.savefig('./output/potential_segments_discounts.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Color by product clicks\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.scatter(df_unscaled['total_time_spent'], df_unscaled['total_purchases'], \n",
    "            c=df_unscaled['product_click'], cmap='viridis', alpha=0.7, s=50)\n",
    "plt.colorbar(label='Product Clicks')\n",
    "plt.title('Potential Customer Segments by Product Clicks')\n",
    "plt.xlabel('Total Time Spent')\n",
    "plt.ylabel('Total Purchases')\n",
    "plt.grid(linestyle='--', alpha=0.5)\n",
    "plt.savefig('./output/potential_segments_clicks.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Processed Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save PCA results\n",
    "pca_df.to_csv('./output/pca_results.csv', index=False)\n",
    "\n",
    "# Save feature loadings\n",
    "loading_df.to_csv('./output/pca_feature_loadings.csv')\n",
    "\n",
    "print(\"EDA results saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of EDA Findings\n",
    "\n",
    "From our exploratory data analysis, we can observe:\n",
    "\n",
    "1. **Feature Distributions**: \n",
    "   - We observed various distributions across features, some with potential outliers\n",
    "   - These distributions may indicate the presence of different customer segments\n",
    "\n",
    "2. **Correlations**:\n",
    "   - Identified relationships between key features like time spent and product clicks\n",
    "   - Some expected correlations between discount usage and purchasing behavior\n",
    "\n",
    "3. **PCA Results**:\n",
    "   - The first two/three principal components capture a significant portion of variance\n",
    "   - Visual inspection of the PCA plot suggests potential clusters\n",
    "\n",
    "4. **Potential Segments**:\n",
    "   - Initial visualization suggests the presence of distinct customer segments\n",
    "   - We can see patterns that align with the expected segments (Bargain Hunters, High Spenders, Window Shoppers)\n",
    "\n",
    "These insights will guide our clustering approach in the next notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
