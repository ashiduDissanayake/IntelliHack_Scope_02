{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize the Identified Clusters\n",
    "\n",
    "Continuing from the previous notebook, we'll visualize the clusters identified by our best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize clusters in 2D using PCA\n",
    "def visualize_clusters_2d(data, labels, title=\"Cluster Visualization\", save_path=None):\n",
    "    # Apply PCA for visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    principal_components = pca.fit_transform(data)\n",
    "    \n",
    "    # Create a dataframe with principal components and cluster labels\n",
    "    pca_df = pd.DataFrame(\n",
    "        data=principal_components,\n",
    "        columns=['PC1', 'PC2']\n",
    "    )\n",
    "    pca_df['Cluster'] = labels\n",
    "    \n",
    "    # Create scatter plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.scatterplot(x='PC1', y='PC2', hue='Cluster', data=pca_df, palette='viridis', s=80, alpha=0.8)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)', fontsize=12)\n",
    "    plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)', fontsize=12)\n",
    "    plt.grid(linestyle='--', alpha=0.5)\n",
    "    plt.legend(title='Cluster', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Create interactive scatter plot using plotly\n",
    "    fig = px.scatter(\n",
    "        pca_df, \n",
    "        x='PC1', \n",
    "        y='PC2', \n",
    "        color='Cluster',\n",
    "        title=title,\n",
    "        labels={\n",
    "            'PC1': f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)',\n",
    "            'PC2': f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)'\n",
    "        }\n",
    "    )\n",
    "    fig.update_traces(marker=dict(size=10))\n",
    "    \n",
    "    if save_path:\n",
    "        html_path = save_path.replace('.png', '.html')\n",
    "        fig.write_html(html_path)\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    return pca_df, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize clusters in 3D using PCA\n",
    "def visualize_clusters_3d(data, labels, title=\"3D Cluster Visualization\", save_path=None):\n",
    "    # Apply PCA for visualization\n",
    "    pca = PCA(n_components=3)\n",
    "    principal_components = pca.fit_transform(data)\n",
    "    \n",
    "    # Create a dataframe with principal components and cluster labels\n",
    "    pca_df = pd.DataFrame(\n",
    "        data=principal_components,\n",
    "        columns=['PC1', 'PC2', 'PC3']\n",
    "    )\n",
    "    pca_df['Cluster'] = labels\n",
    "    \n",
    "    # Create interactive 3D scatter plot\n",
    "    fig = px.scatter_3d(\n",
    "        pca_df, \n",
    "        x='PC1', \n",
    "        y='PC2', \n",
    "        z='PC3',\n",
    "        color='Cluster',\n",
    "        title=title,\n",
    "        labels={\n",
    "            'PC1': f'PC1 ({pca.explained_variance_ratio_[0]:.2%})',\n",
    "            'PC2': f'PC2 ({pca.explained_variance_ratio_[1]:.2%})',\n",
    "            'PC3': f'PC3 ({pca.explained_variance_ratio_[2]:.2%})'\n",
    "        }\n",
    "    )\n",
    "    fig.update_traces(marker=dict(size=5))\n",
    "    \n",
    "    if save_path:\n",
    "        html_path = save_path.replace('.png', '.html')\n",
    "        fig.write_html(html_path)\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    return pca_df, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clusters found by each algorithm in 2D\n",
    "for alg in ['kmeans', 'gmm', 'hierarchical']:\n",
    "    labels = clustering_results[alg]['labels']\n",
    "    title = f\"{alg.capitalize()} Clustering (k=3)\"\n",
    "    save_path = f\"./output/{alg}_clusters.png\"\n",
    "    pca_df, pca = visualize_clusters_2d(features_df, labels, title=title, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the best model's clusters in 3D\n",
    "best_labels = clustering_results[best_3_cluster_algorithm]['labels']\n",
    "title = f\"{best_3_cluster_algorithm.capitalize()} Clustering 3D (k=3)\"\n",
    "save_path = f\"./output/{best_3_cluster_algorithm}_clusters_3d.png\"\n",
    "pca_3d_df, pca_3d = visualize_clusters_3d(features_df, best_labels, title=title, save_path=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Examine Cluster Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster labels to the original unscaled dataframe for interpretation\n",
    "df_with_clusters = df_unscaled.copy()\n",
    "df_with_clusters['Cluster'] = final_labels\n",
    "\n",
    "# Get the distribution of clusters\n",
    "cluster_counts = df_with_clusters['Cluster'].value_counts()\n",
    "cluster_percentages = cluster_counts / len(df_with_clusters) * 100\n",
    "\n",
    "# Print cluster distribution\n",
    "print(\"Cluster Distribution:\")\n",
    "for cluster, count in cluster_counts.iteritems():\n",
    "    print(f\"Cluster {cluster}: {count} customers ({cluster_percentages[cluster]:.2f}%)\")\n",
    "\n",
    "# Plot cluster distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = cluster_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title('Cluster Size Distribution', fontsize=14)\n",
    "plt.xlabel('Cluster', fontsize=12)\n",
    "plt.ylabel('Number of Customers', fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add data labels on top of each bar\n",
    "for i, v in enumerate(cluster_counts):\n",
    "    ax.text(i, v+5, str(v), ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./output/cluster_distribution.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cluster profiles (mean of each feature for each cluster)\n",
    "cluster_profiles = df_with_clusters.groupby('Cluster').mean()\n",
    "\n",
    "# Display cluster profiles\n",
    "print(\"Cluster Profiles (Mean Values):\")\n",
    "display(cluster_profiles)\n",
    "\n",
    "# Visualize cluster profiles with a heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cluster_profiles, annot=True, cmap='viridis', fmt='.2f')\n",
    "plt.title('Cluster Profiles (Mean Values)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./output/cluster_profiles_heatmap.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create box plots for each feature by cluster\n",
    "feature_cols = [col for col in df_with_clusters.columns if col != 'customer_id' and col != 'Cluster']\n",
    "num_features = len(feature_cols)\n",
    "\n",
    "plt.figure(figsize=(15, num_features * 4))\n",
    "\n",
    "for i, feature in enumerate(feature_cols):\n",
    "    plt.subplot(num_features, 1, i+1)\n",
    "    sns.boxplot(x='Cluster', y=feature, data=df_with_clusters, palette='viridis')\n",
    "    plt.title(f'Distribution of {feature} by Cluster', fontsize=14)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "plt.savefig('./output/cluster_feature_distributions.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create radar chart to visualize cluster profiles\n",
    "# First, normalize the values for better visualization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "cluster_profiles_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(cluster_profiles),\n",
    "    index=cluster_profiles.index,\n",
    "    columns=cluster_profiles.columns\n",
    ")\n",
    "\n",
    "# Create radar chart\n",
    "categories = feature_cols\n",
    "fig = go.Figure()\n",
    "\n",
    "for i, cluster in enumerate(cluster_profiles_scaled.index):\n",
    "    values = cluster_profiles_scaled.loc[cluster].values.tolist()\n",
    "    values.append(values[0])  # Close the loop\n",
    "    \n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=values,\n",
    "        theta=categories + [categories[0]],  # Close the loop\n",
    "        fill='toself',\n",
    "        name=f'Cluster {cluster}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    polar=dict(\n",
    "        radialaxis=dict(\n",
    "            visible=True,\n",
    "            range=[0, 1]\n",
    "        )\n",
    "    ),\n",
    "    title='Cluster Profiles (Normalized)',\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.write_html('./output/cluster_profiles_radar.html')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Clustering Results for Further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the clustered data with customer IDs\n",
    "# Check if customer_id exists in the dataset\n",
    "if 'customer_id' in df_unscaled.columns:\n",
    "    customer_df = df_with_clusters[['customer_id', 'Cluster']]\n",
    "    customer_df.to_csv('./output/customer_clusters.csv', index=False)\n",
    "    print(f\"Saved customer cluster assignments to './output/customer_clusters.csv'\")\n",
    "    \n",
    "# Save the full dataset with cluster labels\n",
    "df_with_clusters.to_csv('./output/customer_data_with_clusters.csv', index=False)\n",
    "print(f\"Saved full dataset with cluster labels to './output/customer_data_with_clusters.csv'\")\n",
    "\n",
    "# Save cluster profiles\n",
    "cluster_profiles.to_csv('./output/cluster_profiles.csv')\n",
    "print(f\"Saved cluster profiles to './output/cluster_profiles.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Initial Segment Interpretation\n",
    "\n",
    "Based on the cluster profiles and our domain knowledge of the expected customer segments, we can begin to interpret what each cluster represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate relative feature importance for each cluster (compared to overall mean)\n",
    "overall_mean = df_unscaled[feature_cols].mean()\n",
    "relative_importance = cluster_profiles.copy()\n",
    "\n",
    "for feature in feature_cols:\n",
    "    relative_importance[feature] = (cluster_profiles[feature] - overall_mean[feature]) / overall_mean[feature]\n",
    "\n",
    "# Display relative importance as percentages\n",
    "print(\"Relative Feature Importance (% difference from overall mean):\")\n",
    "relative_importance_pct = relative_importance.applymap(lambda x: f\"{x*100:.1f}%\")\n",
    "display(relative_importance_pct)\n",
    "\n",
    "# Visualize relative importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(relative_importance, annot=True, cmap='RdYlGn', center=0, fmt='.2f')\n",
    "plt.title('Relative Feature Importance by Cluster', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./output/relative_feature_importance.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the cluster profiles, match clusters to the expected segments\n",
    "# Expected segments: Bargain Hunters, High Spenders, Window Shoppers\n",
    "\n",
    "# Create a dictionary to store interpretations\n",
    "segment_interpretations = {}\n",
    "\n",
    "# You'll need to analyze the relative importance and mean values to determine which cluster matches which segment\n",
    "# This is a simplistic example - you'll need to adapt this based on your actual cluster profiles\n",
    "\n",
    "# For each cluster, determine the matching segment based on feature values\n",
    "for cluster_id in cluster_profiles.index:\n",
    "    profile = cluster_profiles.loc[cluster_id]\n",
    "    rel_profile = relative_importance.loc[cluster_id]\n",
    "    \n",
    "    # Characteristics of Bargain Hunters:\n",
    "    # - High total_purchases\n",
    "    # - Low avg_cart_value\n",
    "    # - High discount_count\n",
    "    bargain_score = 0\n",
    "    if rel_profile['total_purchases'] > 0:\n",
    "        bargain_score += 1\n",
    "    if rel_profile['avg_cart_value'] < 0:\n",
    "        bargain_score += 1\n",
    "    discount_col = 'discount_counts' if 'discount_counts' in rel_profile else 'discount_count'\n",
    "    if rel_profile[discount_col] > 0:\n",
    "        bargain_score += 1\n",
    "    \n",
    "    # Characteristics of High Spenders:\n",
    "    # - Moderate total_purchases\n",
    "    # - High avg_cart_value\n",
    "    # - Low discount_count\n",
    "    spender_score = 0\n",
    "    if abs(rel_profile['total_purchases']) < 0.2:  # Close to average\n",
    "        spender_score += 1\n",
    "    if rel_profile['avg_cart_value'] > 0:\n",
    "        spender_score += 1\n",
    "    if rel_profile[discount_col] < 0:\n",
    "        spender_score += 1\n",
    "    \n",
    "    # Characteristics of Window Shoppers:\n",
    "    # - Low total_purchases\n",
    "    # - High total_time_spent\n",
    "    # - High product_click\n",
    "    # - Low discount_count\n",
    "    shopper_score = 0\n",
    "    if rel_profile['total_purchases'] < 0:\n",
    "        shopper_score += 1\n",
    "    if rel_profile['total_time_spent'] > 0:\n",
    "        shopper_score += 1\n",
    "    if rel_profile['product_click'] > 0:\n",
    "        shopper_score += 1\n",
    "    if rel_profile[discount_col] < 0:\n",
    "        shopper_score += 1\n",
    "    \n",
    "    # Determine the best match\n",
    "    scores = {\n",
    "        'Bargain Hunters': bargain_score,\n",
    "        'High Spenders': spender_score,\n",
    "        'Window Shoppers': shopper_score\n",
    "    }\n",
    "    best_match = max(scores, key=scores.get)\n",
    "    \n",
    "    segment_interpretations[cluster_id] = {\n",
    "        'segment': best_match,\n",
    "        'scores': scores,\n",
    "        'key_characteristics': {\n",
    "            'total_purchases': 'High' if rel_profile['total_purchases'] > 0.2 else \n",
    "                              ('Low' if rel_profile['total_purchases'] < -0.2 else 'Moderate'),\n",
    "            'avg_cart_value': 'High' if rel_profile['avg_cart_value'] > 0.2 else \n",
    "                             ('Low' if rel_profile['avg_cart_value'] < -0.2 else 'Moderate'),\n",
    "            'total_time_spent': 'High' if rel_profile['total_time_spent'] > 0.2 else \n",
    "                               ('Low' if rel_profile['total_time_spent'] < -0.2 else 'Moderate'),\n",
    "            'product_click': 'High' if rel_profile['product_click'] > 0.2 else \n",
    "                           ('Low' if rel_profile['product_click'] < -0.2 else 'Moderate'),\n",
    "            'discount_usage': 'High' if rel_profile[discount_col] > 0.2 else \n",
    "                            ('Low' if rel_profile[discount_col] < -0.2 else 'Moderate')\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Print interpretations\n",
    "for cluster_id, interpretation in segment_interpretations.items():\n",
    "    print(f\"\\nCluster {cluster_id} â†’ {interpretation['segment']}\")\n",
    "    print(\"Segment match scores:\", interpretation['scores'])\n",
    "    print(\"Key characteristics:\")\n",
    "    for characteristic, level in interpretation['key_characteristics'].items():\n",
    "        print(f\"  - {characteristic}: {level}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the final segment mappings\n",
    "segment_mapping = {cluster_id: interp['segment'] for cluster_id, interp in segment_interpretations.items()}\n",
    "segment_df = pd.DataFrame({\n",
    "    'Cluster': list(segment_mapping.keys()),\n",
    "    'Segment': list(segment_mapping.values())\n",
    "})\n",
    "\n",
    "# Rename the clusters in the original dataframe\n",
    "df_with_segments = df_with_clusters.copy()\n",
    "df_with_segments['Segment'] = df_with_segments['Cluster'].map(segment_mapping)\n",
    "\n",
    "# Save the segment mapping\n",
    "segment_df.to_csv('./output/segment_mapping.csv', index=False)\n",
    "print(f\"Saved segment mapping to './output/segment_mapping.csv'\")\n",
    "\n",
    "# Save the customer data with segment labels\n",
    "df_with_segments.to_csv('./output/customer_data_with_segments.csv', index=False)\n",
    "print(f\"Saved customer data with segments to './output/customer_data_with_segments.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we have:\n",
    "\n",
    "1. Found the optimal number of clusters using multiple metrics\n",
    "2. Applied different clustering algorithms (K-Means, GMM, Hierarchical, DBSCAN)\n",
    "3. Compared the performance of these algorithms\n",
    "4. Selected the best model based on evaluation metrics\n",
    "5. Visualized the identified clusters\n",
    "6. Examined cluster characteristics\n",
    "7. Interpreted the clusters as customer segments\n",
    "\n",
    "We have successfully identified three distinct customer segments that align with our domain knowledge:\n",
    "\n",
    "1. **Bargain Hunters**: Customers who make frequent purchases of low-value items and rely heavily on discounts\n",
    "2. **High Spenders**: Customers who make moderate purchases of high-value items without relying on discounts\n",
    "3. **Window Shoppers**: Customers who spend significant time browsing many products but rarely make purchases\n",
    "\n",
    "These segments provide valuable insights for targeted marketing strategies. In the next notebook, we'll perform a more in-depth analysis of these segments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
